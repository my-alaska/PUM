{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metody jądrowe (kernel methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguracja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyjemy bardzo standardowych narzędzi, tych samych, co na laboratorium 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install numpy scipy pandas matplotlib scikit-learn missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duży zbiór danych do klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyjemy najpierw bioinformatycznego zbioru danych [Cod-RNA](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#cod-rna). Pochodzi on z artykułu ([link do wersji Open Access](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-173)):\n",
    "\n",
    "> Uzilov, Andrew V., Joshua M. Keegan, and David H. Mathews. *\"Detection of non-coding RNAs on the basis of predicted secondary structure formation free energy change.\"* BMC bioinformatics 7.1 (2006): 1-30. [link](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-173)\n",
    "\n",
    "[Centralny dogmat biologii molekularnej (central dogma of molecular biology)](https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology) mówi, że przepływ informacji genetycznej przebiega z DNA przez RNA do białek. Innymi słowy, DNA zapisuje informację biologiczną, którą potem koduje RNA, z którego są syntezowane białka.\n",
    "\n",
    "W praktyce nie każde DNA i RNA koduje informacje. Kodujące DNA to zaledwie ok. 1-2% ludzkiego genomu, a reszta pełni różne role, głównie regulacyjne. W szczególności [niekodujące RNA (non-coding RNA, ncRNA)](https://en.wikipedia.org/wiki/Non-coding_RNA) pełni wiele różnych zadań, na przykład:\n",
    "- budują rybosomy odpowiadające za syntezę białek ([rRNA](https://en.wikipedia.org/wiki/Ribosomal_RNA))\n",
    "- transportują informację genetyczną ([tRNA](https://en.wikipedia.org/wiki/Transfer_RNA))\n",
    "- regulują ekspresję genów ([lncRNA](https://en.wikipedia.org/wiki/Long_non-coding_RNA))\n",
    "\n",
    "Nie są znane wszystkie funkcje niekodującego RNA, więc jest to aktywne pole badań. Najpierw trzeba jednak sprawdzić, czy dane RNA w ogóle jest kodujące, czy nie. Taka klasyfikacja jest nieoczywista, i też stanowi pole badań w bioinformatyce. Niektóre hipotezy wskazują, że struktura drugorzędowa RNA ma tutaj znacznie.\n",
    "\n",
    "Struktura pierwszorzędowa kwasu nukleinowego (DNA lub RNA) to po prostu liniowa sekwencja nukleotydów, np. ACCUUGCAUC. Struktura drugorzędowa oznacza ułożenie par nukleotydów (np. G-C, A-U) jednego lub dwóch łańcuchów.  Dla DNA to typowo podwójna helisa, natomiast RNA tworzy już bardzo bogate i złożone struktury. Przewidywanie struktury wyższego rzędu to typowe zadanie ML w bioinformatyce, bo sprawdzanie tego eksperymentalnie jest bardzo drogie.\n",
    "\n",
    "![nucleic_acid_structures.png](nucleic_acid_structures.png)\n",
    "\n",
    "Przykładem algorytmu przewidującego strukturę drugorzędową jest [Dynalign](https://www.sciencedirect.com/science/article/abs/pii/S0022283601953513). Opiera się on na obserwacji, że niektóre struktury drugorzędowe RNA są bardziej stabilne od innych. Struktury o niższej energii są, zgodnie z zasadami termodynamiki, wolniejsze, a zatem stabilniejsze i bardziej prawdopodobne. Algorytm ten dodatkowo realizuje **dopasowanie sekwencji (sequence alignment)**, czyli takie \"przyłożenie\" do siebie sekwencji RNA, żeby jak najwięcej par pasowało do siebie. Wejściem do niego są 2 sekwencje RNA, a wyjściem ilość wolnej energii w optymalnej strukturze drugorzędowej RNA - im mniejsza, tym stabilniejsza jest struktura.\n",
    "\n",
    "Artykuł, z którego pochodzi nasz zbiór danych, zaproponował zastosowanie ML do klasyfikacji, czy dwie sekwencje RNA stanowią niekodujące RNA (ncRNA), czy też nie. Zbiór treningowy zbudowano z blisko 60 tysięcy par sekwencji RNA pochodzących z sekwencjonowania genomu bakterii *Escherichia coli* oraz *Salmonella enterica serovar Typhi (Salmonella typhi)*. Klasą pozytywną jest niekodujące RNA (5S rRNA albo tRNA), a negatywną losowo przemieszane nukleotydy z prawdziwej pary (istnieją do tego algorytmy tzw. sequence shuffling). Klasy są w stosunku 1:2, więc mamy klasyfikację lekko niezbalansowaną. Analogicznie stworzono zbiór testowy o wielkości nieco ponad 270 tysięcy par.\n",
    "\n",
    "Jako cech użyto:\n",
    "- wartości z algorytmu Dynalign\n",
    "- długości krótszej sekwencji\n",
    "- częstotliwości zasad azotowych A/U/C w sekwencji 1 (3 cechy)\n",
    "- częstotliwości zasad azotowych A/U/C w sekwencji 2 (3 cechy)\n",
    "\n",
    "Mamy zatem klasyfikację binarną, umiarkowanie niezbalansowaną, i 8 cech numerycznych. Jako metryk autorzy używają precyzji, czułości, krzywych ROC oraz wartości AUROC.\n",
    "\n",
    "My dla uproszczenia użyjemy F1-score, czyli średniej harmonicznej precyzji (precision) i czułości (recall). Obliczanie prawdopodobieństw w SVMach jest kosztowne i daje raczej niskiej jakości predykcje prawdopodobieństw, więc AUROC nie jest dla nich zbyt wygodną metryką."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oryginalny zbiór jest w formacie `svmlight`, z którego korzystają biblioteki LibSVM i Liblinear. Są one standardowymi implementacjami SVMów. Sam ten format danych jest jednak tekstowy i zajmuje bardzo dużo miejsca, dlatego w tym repozytorium jest już przetworzony do formatu Parquet. Wczytamy teraz dane.\n",
    "\n",
    "Później trzeba dokonać normalizacji cech, tak jak zawsze w SVMach. Tak jak autorzy, wykonamy skalowanie min-max do zakresu [-1, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1 (0.5 punktu)**\n",
    "\n",
    "1. Wczytaj dane treningowe z plików `cod_rna_train.parquet` oraz `cod_rna_test.parquet`.\n",
    "2. Wyodrębnij kolumnę `y` do osobnych zmiennych `y_train` oraz `y_test`.\n",
    "3. Dokonaj skalowania danych do zakresu [-1, 1], tworząc tablice `X_train_scaled` oraz `X_test_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet(\"cod_rna_train.parquet\")\n",
    "test_data = pd.read_parquet(\"cod_rna_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = train_data[\"y\"], test_data[\"y\"]\n",
    "\n",
    "scaler = MinMaxScaler((-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(train_data.drop(\"y\", axis=1))\n",
    "X_test_scaled = scaler.transform(test_data.drop(\"y\", axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skoro dane są gotowe, to wytrenujmy nasz pierwszy klasyfikator - liniowy SVM.\n",
    "\n",
    "W Scikit-learn funkcja kosztu (`loss`) to albo typowy hinge loss, albo squared hinge loss, czyli po prostu podniesiona do kwadratu. Wartość domyślna to `\"squared_hinge\"` - żeby dostać \"typowego\" SVMa, trzeba to zmienić. Jest różniczkowalna i mocniej kara duże błędy, ale jest też bardziej podatna na outliery. Dla zainteresowanych: [przystępny tutorial](https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-hinge-squared-hinge-loss-with-keras.md) oraz artykuł naukowy:\n",
    "\n",
    "C.P. Lee, and C.J. Lin. *\"A study on L2-loss (squared hinge-loss) multiclass SVM.\"* Neural computation 25.5 (2013): 1302-1323.\n",
    "\n",
    "Dodatkowo domyślna liczba iteracji solwera (1000) jest często dość niska, szczególnie przy dużych zbiorach. Zwiększymy to od razu, żeby mieć mniej warningów. Powyżej 10 tysięcy iteracji warningami można się już zazwyczaj nie przejmować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 93.03%\n"
     ]
    }
   ],
   "source": [
    "clf_linear_svc = LinearSVC(loss=\"hinge\", max_iter=10000, random_state=0)\n",
    "clf_linear_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = clf_linear_svc.predict(X_test_scaled)\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liniowy SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 2 (0.5 punktu)**\n",
    "\n",
    "Wytrenuj regresję logistyczną jako nasz **model baseline'owy**. Nasze bardziej złożone modele SVM muszą być od niego lepsze, żeby był w ogóle sens je rozważać.\n",
    "\n",
    "Użyj regularyzacji L2. Dokonaj tuningu siły regularyzacji (100 wartości) za pomocą 5-krotnej walidacji skrośnej. Jako metryki do tuningu użyj F1-score.\n",
    "\n",
    "Użyj zbalansowanych wag klas. W razie potrzeby zwiększ maksymalną liczbę iteracji solwera. Może się przydać `n_jobs`. Pamiętaj o ustawieniu `random_state=0`.\n",
    "\n",
    "Sprawdź wyniki algorytmu na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9328111269026721"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv_l2 = LogisticRegressionCV(\n",
    "    Cs=100, cv=5, scoring=\"f1\", class_weight=\"balanced\", random_state=0, n_jobs=-1\n",
    ")\n",
    "logreg_cv_l2.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = logreg_cv_l2.predict(X_test_scaled)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasz SVM bez żadnego tuningu jest zasadniczo tak dobry, jak regresja logistyczna z tuningiem - całkiem nieźle. No ale czas teraz na tuning samego SVMa.\n",
    "\n",
    "Najpierw warto wiedzieć jeszcze parę rzeczy o implementacji użytej w Scikit-learn, korzystającej pod spodem z Liblinear.\n",
    "\n",
    "Argument `dual` wyznacza, czy skorzystać z postaci primal, czy dual. Jeżeli liczba próbek jest znacznie większa od liczby cech, albo ogółem mamy sporo próbek, to lepiej użyć primal `dual=False`. Niestety, wtedy mamy do dyspozycji tylko funkcję kosztu `squared_hinge`.\n",
    "\n",
    "SVM jest stricte jednowątkowy (sekwencyjny), więc równoległość można wykorzystać przy tuningu hiperparametrów. Zdecydowanie warto użyć tu `n_jobs=-1`.\n",
    "\n",
    "**Uwaga:** jako że osobne joby są tworzone jako osobne procesy, to wyłączenie `ConvergenceWarning` jest nietrywialne, a czasem niemożliwe. Sugeruję to po prostu zignorować.\n",
    "\n",
    "**Zadanie 3 (1 punkt)**\n",
    "\n",
    "Dokonaj tuningu hiperparametru `C` liniowego SVM. Użyj 5-krotnej walidacji skrośnej, wybierając model o najwyższym F1-score. Użyj zbalansowanych wag klas i funkcji kosztu hinge loss. Pamiętaj o stałym `random_state`.\n",
    "\n",
    "Zastosuj iteracyjne zagęszczanie siatki. Najpierw sprawdź wartości z zakresu `[1e-3, 1e-2, 1e-1, 1, 1e1, 1e2]` i znajdź optymalną wartość `C`. Następnie wedle własnego uznania zagęść siatkę wokół znalezionego optymalnego C. Może się przydać `np.linspace()` albo `list(range())`. Jeżeli w takiej operacji wychodzi optymalne `C` na granicy (najmniejsze albo największe możliwe), to warto sprawdzić większe wartości niż dotychczas rozważane. Powtórz takie działanie 2-3 razy. W praktyce jednak `C` większe niż kilkaset nie ma sensu w kontekście SVMów.\n",
    "\n",
    "Wypisz ostatecznę znalezioną optymalną wartość odwrotności siły optymalizacji `C`. Sprawdź wynik na zbiorze testowym. Czy udało się przebić baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piotr\\anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LinearSVC(loss=&#x27;hinge&#x27;, max_iter=10000, random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LinearSVC(loss=&#x27;hinge&#x27;, max_iter=10000, random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(loss=&#x27;hinge&#x27;, max_iter=10000, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(loss=&#x27;hinge&#x27;, max_iter=10000, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LinearSVC(loss='hinge', max_iter=10000, random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(\n",
    "    loss=\"hinge\",\n",
    "    max_iter=10000,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    #     \"C\": [0.001, 0.01, 0.1, 1., 10, 100]\n",
    "    #     \"C\": np.arange(1,100,10)\n",
    "    \"C\": np.arange(60, 70, 1)\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "\n",
    "cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9303268192194198"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cv.predict(X_test_scaled)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wynik nie różni się znacząco od tego który uzyskaliśmy na początku. Stosując squared hinge loss wynik jest słabszy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Może się to jeszcze uda poprawić - w końcu w artykule autorzy używali kernel SVM, a nie liniowego!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel SVM w Scikit-learn jest implementowany w klasie `SVC`. Wypróbujmy podstawową wersję, bez tuningu hiperparametrów. Przy okazji wiemy, że złożoność kernel SVM to co najmniej $O(n^2)$ - zobaczmy, ile to zajmuje w praktyce.\n",
    "\n",
    "Warto zawsze ustawić nieco wyższą wartość `cache_size` niż domyślna. Jest to ilość MB na cache'owanie obliczonych wartości kerneli. Warto jednak uważać na zbyt duże wartości:\n",
    "- wartości ponad 2000 mogą [powodować problemy przez buga w LibSVM](https://github.com/scikit-learn/scikit-learn/issues/8012)\n",
    "- sama alokacja dużej ilości pamięci (ciągłej!) może zajmować dużo czasu\n",
    "- nie wszystkie wartości kerneli będą używane często, więc nie wszystkie jest sens cache'ować"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 94.92%\n",
      "Training time: 130.6237461566925 s\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(cache_size=512, class_weight=\"balanced\", random_state=0)\n",
    "start_time = time()\n",
    "clf_kernel_svc.fit(X_train_scaled, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test_scaled)\n",
    "\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Training time: {training_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wynik jest ewidentnie lepszy, bez żadnego tuningu! Zajmuje to jednak sporo czasu. Ale nasz zbiór treningowy to ok. 60 tysięcy, a testowy 270 tysięcy - może to predykcja tyle zajmuje, a nie sam trening?\n",
    "\n",
    "**Zadanie 4 (1 punkt)**\n",
    "\n",
    "1. Sprawdź liczbę support vectors dla liniowego i kernel SVM. Sprawdź, jaki procent wszystkich punktów one stanowią. Czy rzadkość (sparsity) została osiągnięta? Może się przydać [ten przykład](https://scikit-learn.org/stable/auto_examples/svm/plot_linearsvc_support_vectors.html), żeby zliczyć support vectors dla liniowego SVM (`X` to u nas `X_train_scaled`).\n",
    "2. Porównaj czas predykcji na zbiorze testowym dla regresji logistycznej, liniowego SVM i kernel SVM. Uwzględniając rozmiar zbioru testowego, czy twoim zdaniem to dużo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 47.216084241867065 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "decision_function = clf_kernel_svc.decision_function(X_train_scaled)\n",
    "end_time = time()\n",
    "prediction_time = end_time - start_time\n",
    "print(f\"Prediction time: {prediction_time} s\")\n",
    "\n",
    "support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8449 0.14191651969429747\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(support_vector_indices), len(support_vector_indices) / X_train_scaled.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.0029973983764648438 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "decision_function = clf_linear_svc.decision_function(X_train_scaled)\n",
    "end_time = time()\n",
    "prediction_time = end_time - start_time\n",
    "print(f\"Prediction time: {prediction_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.0019941329956054688 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "decision_function = logreg_cv_l2.decision_function(X_train_scaled)\n",
    "end_time = time()\n",
    "prediction_time = end_time - start_time\n",
    "print(f\"Prediction time: {prediction_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support vector stanowią ponad 14% zbioru treningowego to bardzo duzo. dodatkowo niezwykle duży czas predykcji może nie być pożądany w pewnych przypadkach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taki zbiór jest już dość ekstremalny dla kernel SVM. Tego algorytmu w praktyce nie stosuje się wprost dla zbiorów wielkości dziesiątek tysięcy próbek treningowych, bo byłoby to zbyt wolne. Można tu natomiast zastosować podobną sztuczkę, co z kNN i ANN, czyli aproksymować - w tym wypadku macierz kerneli. Dotyczy tego zadanie dodatkowe.\n",
    "\n",
    "Dodatkowo implementacja ze Scikit-learn potrafi być zaskakująco wolna. W praktyce LibSVM, użyty jako [samodzielna biblioteka](https://pypi.org/project/libsvm-official/), potrafi być o wiele szybszy. Ma za to dużo brzydszy interfejs.\n",
    "\n",
    "W praktyce kernel SVM jest używany najczęściej, kiedy mamy mało danych i trzeba bardzo dokładnego klasyfikatora, a jego duży koszt nie jest tak odczuwalny."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mały zbiór danych do klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako drugi zbiór wykorzystamy [Iranian Churn Dataset](https://archive.ics.uci.edu/ml/datasets/Iranian+Churn+Dataset) ([Kaggle](https://www.kaggle.com/datasets/royjafari/customer-churn)). Dotyczy on klasyfikacji, czy dany klient telekomunikacyjny zmieni dostawcę, czyli nastąpi tzw. odpływ klienta (*customer churn*). Jest to bardzo ważne i częste zadanie w telekomunikacji i usługach, szczególnie w biznesach, gdzie pozyskanie całkiem nowych klientów jest bardzo trudne albo praktycznie niemożliwe, a trzeba ich w praktyce odebrać konkurencji. To właśnie sytuacja firm telekomunikacyjnych - telefon czy internet ma praktycznie każdy, więc zdobywanie nowych klientów jest drogie. Dużo bardziej opłaca się identyfikować \"ryzykownych\" klientów i ich zachęcić do pozostania, np. promocjami.\n",
    "\n",
    "Dane zostały pozyskane z irańskich firm telekomunikacyjnych (konkretnie z call center obsługującego takie firmy). [Historia telekomunikacji w Iranie](https://en.wikipedia.org/wiki/Communications_in_Iran) jest ciekawa sama w sobie i pokazuje, czemu w tym kraju to było szczególnie ważne. Iran w 2008 roku miał populację ponad 80 milionów ludzi, z czego około 56% poniżej 25 roku życia - idealny i duży rynek dla nowych technologii. Ponadto samo zainteresowanie było ogromne, a tempo rozwoju kraju oraz prywatyzacja państwowych spółek stworzyły niesamowicie konkurencyjny rynek. Churn prediction stało się bardzo ważnym finansowo zadaniem dla wielu spółek.\n",
    "\n",
    "Z perspektywy ML, churn prediction to praktycznie zawsze klasyfikacja binarna i niezbalanansowana - zwykle mało który klient odchodzi.\n",
    "\n",
    "Zbiór ten został zebrany przez autorów na potrzeby artykułu:\n",
    "\n",
    "> Keramati, Abbas, and Seyed MS Ardabili. *\"Churn analysis for an Iranian mobile operator.\"* Telecommunications Policy 35.4 (2011): 344-356.\n",
    "\n",
    "Churn prediction z użyciem tego zbioru zostało przez nich zastosowane w artykułach:\n",
    "\n",
    "> Keramati, Abbas, et al. *\"Improved churn prediction in telecommunication industry using data mining techniques.\"* Applied Soft Computing 24 (2014): 994-1012.\n",
    "\n",
    "> Jafari-Marandi, Ruholla, et al. *\"Optimum profit-driven churn decision making: innovative artificial neural networks in telecom industry.\"* Neural Computing and Applications 32 (2020): 14929-14962.\n",
    "\n",
    "Dane są wysokiej jakości - ludzi monitorowano przez 12 miesięcy, aby uzyskać miarodajną informację w czasie, czy odejdą do innego operatora. Dodatkowo nie mają wartości brakujących i outlierów, a wszystkie zmienne są numeryczne. Zastosowaną w artykułach metryką jest F1-score.\n",
    "\n",
    "Zbiór został wzięty z Kaggle (opublikował go tam Ruholla Jafari-Marandi). W dodatku do zmiennych opisanych na stronie UCI, zawiera on oszacowaną wartość FP i FN dla każdego klienta. Wykorzystamy to później - w końcu utrata dużo płacącego klienta jest bardziej kosztowna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 5 (1 punkt)**\n",
    "\n",
    "1. Wczytaj dane z pliku `customer_churn_data.csv`.\n",
    "2. Wyodrębnij kolumny do zmiennych:\n",
    "   - `Churn` do zmiennej `y`\n",
    "   - `FN` do zmiennej `fn_cost`\n",
    "   - `FP` do zmiennej `fp_cost`\n",
    "3. Narysuj wykres słupkowy (bar plot) częstości klas. Pamiętaj o opisaniu wykresu.\n",
    "4. Podziel zbiór na treningowy i testowy w proporcjach 75%-25% ze stratyfikacją. Pamiętaj o stałym `random_state=0`. Uwaga - podziel też `fn_cost` oraz `fp_cost` na treningowe i testowe.\n",
    "5. Dokonaj standaryzacji zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4370</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>197.640</td>\n",
       "      <td>177.8760</td>\n",
       "      <td>69.7640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>46.035</td>\n",
       "      <td>41.4315</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2453</td>\n",
       "      <td>60</td>\n",
       "      <td>359</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1536.520</td>\n",
       "      <td>1382.8680</td>\n",
       "      <td>203.6520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4198</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>240.020</td>\n",
       "      <td>216.0180</td>\n",
       "      <td>74.0020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2393</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>145.805</td>\n",
       "      <td>131.2245</td>\n",
       "      <td>64.5805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n",
       "0              8          0                    38               0   \n",
       "1              0          0                    39               0   \n",
       "2             10          0                    37               0   \n",
       "3             10          0                    38               0   \n",
       "4              3          0                    38               0   \n",
       "\n",
       "   Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "0            4370                71                 5   \n",
       "1             318                 5                 7   \n",
       "2            2453                60               359   \n",
       "3            4198                66                 1   \n",
       "4            2393                58                 2   \n",
       "\n",
       "   Distinct Called Numbers  Age Group  Tariff Plan  Status  Age  \\\n",
       "0                       17          3            1       1   30   \n",
       "1                        4          2            1       2   25   \n",
       "2                       24          3            1       1   30   \n",
       "3                       35          1            1       1   15   \n",
       "4                       33          1            1       1   15   \n",
       "\n",
       "   Customer Value         FN        FP  Churn  \n",
       "0         197.640   177.8760   69.7640      0  \n",
       "1          46.035    41.4315   60.0000      0  \n",
       "2        1536.520  1382.8680  203.6520      0  \n",
       "3         240.020   216.0180   74.0020      0  \n",
       "4         145.805   131.2245   64.5805      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df = pd.read_csv(\"customer_churn_data.csv\")\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = churn_df[\"Churn\"]\n",
    "fn_cost = churn_df[\"FN\"]\n",
    "fp_cost = churn_df[\"FP\"]\n",
    "X = churn_df.drop([\"Churn\", \"FN\", \"FP\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3150,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = (y.value_counts() / y.shape[0]).plot.bar()\n",
    "plt.xlabel(\"class\")\n",
    "plt.ylabel(\"occurrence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    fp_cost_train,\n",
    "    fp_cost_test,\n",
    "    fn_cost_train,\n",
    "    fn_cost_test,\n",
    ") = train_test_split(X, y, fp_cost, fn_cost, test_size=0.25, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 6 (1.5 punktu)**\n",
    "\n",
    "1. Wytrenuj regresję logistyczną jako baseline, dokonując tuningu analogicznie do zadania 2. Pamiętaj o ustawieniu `random_state=0`. Zmierz czas treningu (włącznie z tuningiem). Sprawdź F1-score na zbiorze testowym\n",
    "2. Wytrenuj liniowy SVM:\n",
    "   - ustaw maksymalnie 10000 iteracji i zbalansowane wagi klas\n",
    "   - dokonaj tuningu hiperparametru `C` za pomocą 5-krotnej walidacji skrośnej\n",
    "   - sprawdź 100 wartości z zakresu od $10^{-2}$ do $10^2$\n",
    "   - wypisz znalezioną optymalną wartość `C`\n",
    "   - wybierz model o najwyższym F1-score\n",
    "   - zmierz czas treningu (włącznie z tuningiem)\n",
    "   - sprawdź F1-score na zbiorze testowym\n",
    "   - pamiętaj o ustawieniu `random_state=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7229511737823486 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6104651162790697"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time()\n",
    "logreg_cv_l2 = LogisticRegressionCV(\n",
    "    Cs=100, cv=5, scoring=\"f1\", class_weight=\"balanced\", random_state=0, n_jobs=-1\n",
    ")\n",
    "logreg_cv_l2.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "prediction_time = end_time - start_time\n",
    "print(prediction_time, \"s\")\n",
    "\n",
    "y_pred = logreg_cv_l2.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.575459003448486 s\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(loss=\"hinge\", max_iter=10000, random_state=0, class_weight=\"balanced\")\n",
    "\n",
    "param_grid = {\"C\": np.power(10.0, np.arange(-2, 2, 4 / 100))}\n",
    "\n",
    "cv = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time()\n",
    "cv.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "prediction_time = end_time - start_time\n",
    "print(prediction_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.48074602497766"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.591304347826087"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cv.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oba wyniki nie wyglądają zadowalająco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 7 (2 punkty)**\n",
    "\n",
    "1. Wytrenuj kernel SVM z domyślnymi hiperparametrami:\n",
    "   - ustaw zbalansowane wagi klas\n",
    "   - zmierz czas treningu (włącznie z tuningiem)\n",
    "   - sprawdź F1-score na zbiorze testowym\n",
    "   - zmierz czas treningu\n",
    "   - pamiętaj o ustawieniu `random_state=0`\n",
    "2. Wytrenuj kernel SVM z tuningiem hiperparametrów:\n",
    "   - sprawdź kilka siatek hiperparametrów (`param_grid` może być listą słowników!)\n",
    "   - dla kerneli RBF sprawdź 20 wartości `C` z zakresu od $10^{-2}$ do $10^2$, a dla `gamma` sprawdź wartość `\"scale\"` oraz 20 wartości z zakresu od $10^{-2}$ do $10^2$\n",
    "   - dla kernela wielomianowego sprawdź 100 wartości `C` z zakresu od $10^{-2}$ do $10^2$ oraz stopnie wielomianu z zakresu [2, 5]\n",
    "   - dla kernela sigmoidalnego sprawdź te same zakresy wartości, co dla RBF\n",
    "3. Dokonaj analizy hiperparametrów po tuningu:\n",
    "   - sprawdź, dla jakich hiperparametrów osiągnięto najwyższy wynik walidacji skrośnej\n",
    "   - sprawdź, jaki był najlepszy wynik osiągnięty dla każdego z trzech kerneli\n",
    "   - wypisz hiperparametry dla każdego z tych przypadków\n",
    "   - który kernel wymagał najmocniejszej regularyzacji i jak sądzisz, czemu ten?\n",
    "   - wytrenuj SVM dla optymalnych hiperparametrów dla każdego z trzech kerneli i sprawdź F1-score na zbiorze testowym\n",
    "   - czy udało się dobrze oszacować wynik za pomocą walidacji skrośnej, tj. czy faktycznie kernel o najwyższym wyniku walidacyjnym miał najwyższy wynik testowy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 65.71%\n",
      "Training time: 0.09222865104675293 s\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(cache_size=512, class_weight=\"balanced\", random_state=0)\n",
    "start_time = time()\n",
    "clf_kernel_svc.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test)\n",
    "\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Training time: {training_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.90355563163757 s\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(cache_size=512, class_weight=\"balanced\", random_state=0)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"C\": np.power(10.0, np.arange(-2, 2, 1 / 5)),\n",
    "        \"gamma\": [\"scale\"],\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"C\": np.power(10.0, np.arange(-2, 2, 1 / 5)),\n",
    "        \"gamma\": np.power(10.0, np.arange(-2, 2, 1 / 5)),\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": [\"poly\"],\n",
    "        \"C\": np.power(10.0, np.arange(-2, 2, 1 / 25)),\n",
    "        \"degree\": [2, 3, 4, 5],\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": [\"sigmoid\"],\n",
    "        \"C\": np.power(10.0, np.arange(-2, 2, 1 / 5)),\n",
    "        \"gamma\": [\"scale\"],\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": [\"sigmoid\"],\n",
    "        \"C\": np.power(10.0, np.arange(-2, 2, 1 / 5)),\n",
    "        \"gamma\": np.power(10.0, np.arange(-2, 2, 1 / 5)),\n",
    "    },\n",
    "]\n",
    "\n",
    "cv = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time()\n",
    "cv.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "prediction_time = end_time - start_time\n",
    "print(prediction_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 25.11886431509577, 'gamma': 0.6309573444801927, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.328917</td>\n",
       "      <td>0.047990</td>\n",
       "      <td>0.183509</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.650877</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266085</td>\n",
       "      <td>0.049692</td>\n",
       "      <td>0.153789</td>\n",
       "      <td>0.013086</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 0.015848931924611134, 'gamma': 'scale', ...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.652362</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.235170</td>\n",
       "      <td>0.048027</td>\n",
       "      <td>0.130650</td>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 0.025118864315095794, 'gamma': 'scale', ...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.652362</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.172737</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.109308</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.039811</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 0.03981071705534971, 'gamma': 'scale', '...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.651806</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156979</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.099733</td>\n",
       "      <td>0.020575</td>\n",
       "      <td>0.063096</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 0.0630957344480193, 'gamma': 'scale', 'k...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.673171</td>\n",
       "      <td>0.594340</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.036155</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time   param_C  \\\n",
       "0       0.328917      0.047990         0.183509        0.010686      0.01   \n",
       "1       0.266085      0.049692         0.153789        0.013086  0.015849   \n",
       "2       0.235170      0.048027         0.130650        0.009398  0.025119   \n",
       "3       0.172737      0.010618         0.109308        0.003868  0.039811   \n",
       "4       0.156979      0.007817         0.099733        0.020575  0.063096   \n",
       "\n",
       "  param_gamma param_kernel param_degree  \\\n",
       "0       scale          rbf          NaN   \n",
       "1       scale          rbf          NaN   \n",
       "2       scale          rbf          NaN   \n",
       "3       scale          rbf          NaN   \n",
       "4       scale          rbf          NaN   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0     {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}           0.636364   \n",
       "1  {'C': 0.015848931924611134, 'gamma': 'scale', ...           0.636364   \n",
       "2  {'C': 0.025118864315095794, 'gamma': 'scale', ...           0.636364   \n",
       "3  {'C': 0.03981071705534971, 'gamma': 'scale', '...           0.636364   \n",
       "4  {'C': 0.0630957344480193, 'gamma': 'scale', 'k...           0.650000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.689655           0.666667           0.583732           0.677966   \n",
       "1           0.689655           0.666667           0.583732           0.685393   \n",
       "2           0.689655           0.666667           0.583732           0.685393   \n",
       "3           0.689655           0.666667           0.580952           0.685393   \n",
       "4           0.689655           0.673171           0.594340           0.692737   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.650877        0.037963              660  \n",
       "1         0.652362        0.039122              645  \n",
       "2         0.652362        0.039122              645  \n",
       "3         0.651806        0.040100              655  \n",
       "4         0.659981        0.036155              580  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8580881605232251\n"
     ]
    }
   ],
   "source": [
    "best_rbf = results_df.loc[results_df[\"param_kernel\"] == \"rbf\"][\"mean_test_score\"].max()\n",
    "print(best_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8325899949091706\n"
     ]
    }
   ],
   "source": [
    "best_poly = results_df.loc[results_df[\"param_kernel\"] == \"poly\"][\n",
    "    \"mean_test_score\"\n",
    "].max()\n",
    "print(best_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6586906824553976\n"
     ]
    }
   ],
   "source": [
    "best_sigmoid = results_df.loc[results_df[\"param_kernel\"] == \"sigmoid\"][\n",
    "    \"mean_test_score\"\n",
    "].max()\n",
    "print(best_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 25.11886431509577, 'gamma': 0.6309573444801927, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[results_df[\"mean_test_score\"] == best_rbf].get(\"params\").iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 83.17637711026777, 'degree': 5, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[results_df[\"mean_test_score\"] == best_poly].get(\"params\").iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.0630957344480193, 'gamma': 0.015848931924611134, 'kernel': 'sigmoid'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[results_df[\"mean_test_score\"] == best_sigmoid].get(\"params\").iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 87.69%\n",
      "Training time: 0.1156778335571289 s\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(\n",
    "    cache_size=512,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=0,\n",
    "    **{\"C\": 25.11886431509577, \"gamma\": 0.6309573444801927, \"kernel\": \"rbf\"},\n",
    ")\n",
    "start_time = time()\n",
    "clf_kernel_svc.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test)\n",
    "\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Training time: {training_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 83.02%\n",
      "Training time: 0.08680033683776855 s\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(\n",
    "    cache_size=512,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=0,\n",
    "    **{\"C\": 83.17637711026777, \"degree\": 5, \"kernel\": \"poly\"},\n",
    ")\n",
    "start_time = time()\n",
    "clf_kernel_svc.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test)\n",
    "\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Training time: {training_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 60.00%\n",
      "Training time: 0.1406688690185547 s\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(\n",
    "    cache_size=512,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=0,\n",
    "    **{\"C\": 0.0630957344480193, \"gamma\": 0.015848931924611134, \"kernel\": \"sigmoid\"},\n",
    ")\n",
    "start_time = time()\n",
    "clf_kernel_svc.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test)\n",
    "\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Training time: {training_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faktycznie najlepszy wynik osiągneliśmy dla parametrów wyznaczonych przez cross validation grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie uwzględniliśmy jednak jeszcze faktu, że nasi klienci mają różną wagę. Według badań koszt zyskania klienta jest około 15 razy wyższy od kosztu utrzymania klienta, który jest zagrożony przejściem dla konkurencji. W związku z tym FP i FN mają różną ważnośc. Dodatkowo sami klienci płacą mniej lub więcej, więc to też trzeba uwzględnić. Na szczęście my mamy już to zrobione, bo mamy macierze `fp_cost` oraz `fn_cost` oznaczające koszt pomylenia się na oba sposoby w przypadku każdego klienta.\n",
    "\n",
    "Powinniśmy zatem używać **ważonej metryki (weighted metric)**, która dla każdego przykładu stosuje odpowiednią wagę, i to w zależności od tego, w jaki sposób się pomyliliśmy. Tego typu metryki typowo działają jak funkcje kosztu - im mniejsza wartość, tym lepiej, bo często dosłownie reprezentują koszt, jaki firma musi ponieść przy stosowaniu danego algorytmu. Wykorzystanie takiej metryki to **cost-sensitive classification**.\n",
    "\n",
    "**Zadanie 8 (0.5 punktu)**\n",
    "\n",
    "1. Uzupełnij kod funkcji `churn_cost()`, która oblicza koszt dokonania danej klasyfikacji.\n",
    "2. Stwórz funkcję w postaci akceptowanej przez `GridSearchCV` za pomocą `make_scorer`. Zwróć uwagę, żeby podać do niej prawidłowe argumenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def churn_cost(\n",
    "    y_true: Union[np.ndarray, pd.Series],\n",
    "    y_pred: Union[np.ndarray, pd.Series],\n",
    "    fp_cost: Union[np.ndarray, pd.Series],\n",
    "    fn_cost: Union[np.ndarray, pd.Series],\n",
    ") -> float:\n",
    "    # make sure all data is Numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    fp_cost = np.array(fp_cost)\n",
    "    fn_cost = np.array(fn_cost)\n",
    "\n",
    "    # check which rows are for FP and FN\n",
    "    FP = (1 - y_true) * y_pred\n",
    "    FN = y_true * (1 - y_pred)\n",
    "\n",
    "    # get costs for FP and FN\n",
    "    fp_real_cost = FP * fp_cost\n",
    "    fn_real_cost = FN * fn_cost\n",
    "\n",
    "    # return sum of costs\n",
    "    return fp_real_cost.sum() + fn_real_cost.sum()\n",
    "\n",
    "\n",
    "churn_cost_score = make_scorer(\n",
    "    churn_cost,\n",
    "    average=\"macro\",\n",
    "    greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 9 (1 punkt)**\n",
    "\n",
    "1. Wytrenuj klasyfikatory stały `DummyClassifier`:\n",
    "   - taki, który zawsze przewiduje klasę negatywną (brak zmiany)\n",
    "   - taki, który zawsze przewiduje klasę pozytywną (churn)\n",
    "2. Sprawdź metrykę F1-score oraz nasz nowo zdefiniowany churn cost dla takich rozwiązań na zbiorze testowym. Wykorzystaj `fp_cost_test` oraz `fn_cost_test`.\n",
    "3. Lepiej jest stosować reklamy dla wszystkich, czy po prostu zgodzić się na churn i nic z tym nie robić? Uwzględniając liczbę próbek w zbiorze testowym, czy twoim zdaniem wysoki koszt? Załóż, że walutą są dolary - irański rial zawsze był tak słabą walutą, że i tak używano walut zagranicznych, co widać też w tym zbiorze. Wartość każdego klienta jest typowo wysoka, bo to obliczona tzw. lifetime value - przewidywana potencjalna wartość klienta w przyszłości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trening przez deklarację\n",
    "def DummyPredict(X, churn):\n",
    "    return np.full(X.shape[0], churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = DummyPredict(X_test, 1)\n",
    "y_pred_n = DummyPredict(X_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2719298245614035"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69593.1995"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_cost(y_test, y_pred_p, fp_cost_test, fn_cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15871.644"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_cost(y_test, y_pred_n, fp_cost_test, fn_cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widać, że koszt traktowania wszystkich klientów jako potencjalnie mogących odejść jest kilkukrotnie wyższy niż koszt zaniedbania faktycznych klientów którzy tym zagrażają więc jeśli mamy wybierać w rozwiązaniu identycznym dla wszystkich lepiej po prostu pozwolić im odejść (wiem, że smutno to brzmi). Nie wiem czy koszt w zbiorze testowym jest obliczny jako miesięczny czy dzienny, czy całkowity dla firmy więc nie mogę na pewno stwierdzić czy to dużo czy nie, ale zakładając, że to ostatnia opcja to raczej żędy dziesiątek tysięcy nie są przesadnie ogromne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 10 (1 punkt)**\n",
    "\n",
    "1. Wytrenuj liniowy SVM, wykorzystaj znalezioną wcześniej optymalną wartość `C`. Innych parametrów użyj tak, jak wcześniej. Jaki jest koszt przy wdrożeniu takiego rozwiązania? Ile zyskujemy względem najlepszego rozwiązania z poprzedniego zadania?\n",
    "2. Wytrenuj kernel SVM, wykorzystaj znalezione wcześniej optymalne wartości hiperparametrów. Innych parametrów użyj tak, jak wcześniej. O ile lepszy jest koszt? O ile lepszy jest od modelu liniowego, jakim jest liniowy SVM?\n",
    "3. Czy twoim zdaniem warto wdrażać rozwiązania oparte o ML do takich zadań?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn cost: 1162997.55\n",
      "Training time: 0.22544145584106445 s\n"
     ]
    }
   ],
   "source": [
    "lin_clf = LinearSVC(\n",
    "    loss=\"hinge\",\n",
    "    max_iter=10000,\n",
    "    random_state=0,\n",
    "    class_weight=\"balanced\",\n",
    "    C=52.48074602497766,\n",
    ")\n",
    "\n",
    "start_time = time()\n",
    "lin_clf.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "y_pred = lin_clf.predict(X_test)\n",
    "\n",
    "print(f\"churn cost: {100 * churn_cost(y_test, y_pred,fp_cost_test,fn_cost_test):.2f}\")\n",
    "print(f\"Training time: {training_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn cost: 367668.95\n",
      "Training time: 0.09345030784606934 s\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(\n",
    "    cache_size=512,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=0,\n",
    "    **{\"C\": 25.11886431509577, \"gamma\": 0.6309573444801927, \"kernel\": \"rbf\"},\n",
    ")\n",
    "start_time = time()\n",
    "clf_kernel_svc.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test)\n",
    "\n",
    "print(f\"churn cost: {100 * churn_cost(y_test, y_pred,fp_cost_test,fn_cost_test):.2f}\")\n",
    "print(f\"Training time: {training_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Około trzykrotne zmniejszenie kosztu to faktycznie spory skok. Myślę, że jak najbardziej warto wykorzystać każde narzędzie które może przyczynić się do takiego sysku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie dodatkowe (3 punkty)\n",
    "\n",
    "W przypadku, kiedy zastosowanie kernel SVM wprost byłoby zbyt kosztowne, można zamiast tego przybliżyć cechy kernelowe. Realizują to algorytmy grupy kernel approximation.\n",
    "\n",
    "Metoda Nyströma to algorytm uniwersalny, który potrafi przybliżyć dowolny kernel. Wykorzystuje do tego truncated SVD, czyli przybliża wprost kernel matrix za pomocą macierzy niższej rangi. Ceną tej prostoty i uniwersalności jest nie najlepsza prędkość działania w porównaniu do bardziej specjalistycznych algorytmów. Proste wyprowadzenie tej metody można znaleźć [tutaj](https://stats.stackexchange.com/questions/261149/nystroem-method-for-kernel-approximation).\n",
    "\n",
    "`RBFSampler` w Scikit-learn implementuje metodę Random Kitchen Sinks. Ten algorytm za pomocą próbkowania Monte Carlo przybliża coraz lepiej macierz kernela RBF. W bibliotece Scikit-learn-extra zaimplementowane jest rozwinięcie tego algorytmu o nazwie [Fastfood](https://scikit-learn-extra.readthedocs.io/en/stable/generated/sklearn_extra.kernel_approximation.Fastfood.html), który stosuje nieco bardziej zaawansowany algorytm przybliżający, który powinien być jeszcze szybszy i oszczędniejszy pamięciowo.\n",
    "\n",
    "Hiperparametry tych metod są podobne do zwykłego kernel SVM, ale dodatkowo mamy wymiarowość naszego przybliżenia, czyli `n_components`. Im większe, tym dokładniej przybliżamy, ale też tym więcej mamy cech. Wejściem do metody Nyströma jest macierz cech X, a wyjściem macierz cech kernelowych X mająca rozmiar `n_samples * n_components`. Na takich cechach trenuje się już zwykły liniowy SVM.\n",
    "\n",
    "1. Zaimplementuj `Pipeline` składający się z przybliżenia kernela oraz liniowego SVM: dla metody Nyströma, oraz dla obu algorytmów dla kernela RBF.\n",
    "2. Wytrenuj algorytmy z domyślnymi hiperparametrami. Porównaj jakość predykcji oraz szybkość z liniowym SVM i z kernel SVM. Czy warto dokonać takiej aproksymacji?\n",
    "3. Dokonaj optymalizacji hiperparametrów `C`, `gamma` oraz `n_components`. Czy udało się poprawić wynik względem zwykłego kernel SVM w rozsądnym czasie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// skomentuj tutaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
